# Introduction to Data Structures

    Type of data structure :
    1: Linear Data Structure
    2: Non-Linear Data Structure.

            Linear Data Structure:
                Elements are arranged in one dimension ,also known as linear dimension.
                Example: lists, stack, queue, etc.

            Non-Linear Data Structure
                Elements are arranged in one-many, many-one and many-many dimensions.
                Example: tree, graph, table, etc.

# Basics

    # Logic
         Operators
            - Conditional operator (A -> B) [Implication]
            - Bi-conditional operator (A <-> B) [Bi-Implication]
            - Negations operator (!A) means  not - !
            - And or Or operators
                and - &
                or - |

                (and) operators return true if and only if both operators are true.
                (or) operators return true if at least one operator is true.
                (not) operator inverts a situation or condition: if true it turns it false and vice-versa.
       
        Boolean Algebra
            - Associativity [a + (b + c) = (a + b) + c)]
                    A AND (B AND C) = (A AND B) AND C.
                    A OR (B OR C) = (A OR B) OR C.

            - Distributivity [a × (b + c) = (a × b) + (a × c)]
                    A AND (B OR C) = (A AND B) OR (A AND C).
                    A OR (B AND C) = (A OR B) AND (A OR C).


            # Note:
                Demorgan's Law
                    ANDs can be transformed into ORs and vice versa!

    # Counting
        - Multiplying 
                if an event happens in n different ways and another event happens in m different ways the number of different ways both events can happens is 
                (n * m)

        - Combinations 
                - with rep
                    C(n,r) = n - r - 1 / (n - 1)r
                - without rep 
                    C(n,r) = n! / (n - r) r!
        - Permutations 
                - with rep
                    P(n,r) = n^r
                - without rep 
                    P(n,r) = n! / (n - r)!

    # Probability

            - Event 
                    p(E) = |E| / |S|
                        |E| = event 
                        |S| = sample space : all the possible outcomes 

            - Conditional 
                the probability that event  A  has occurred in a trial of a random experiment for which it is known that event  B  has definitely occurred.

                    p(A/B) = p(A n B) / p(B)

            - Independent 
                For: Events  A  and  B  are independent
                    p(B) = p(B/A)

                        p(A n B) = p(A) * p(B)
                            -> if true then its independent

    # Logarithm?
        is the power to which a number muse be raised in order to get some other number.

            How to write them?

                in general you write log followed by the base num as a subscript 
                the most common log are base 10 and natural log 
                    Ex. Log
                        Log a = r
                    
                    natural log 
                        ln
                        ln a = r

            Rules of Log:
                1.   br = a is the equivalent to logb a=r (This is the definition of a logarithm.)
                2.   log 0 is undefined.
                3.   log 1 = 0
                4.   log (P*Q) = log P + log Q
                5.   log (P/Q) = log P - log Q
                6.   log (Pt) = t *log P
                7.   10(log a) = a (in the case of natural logarithms, e(ln a) = a)
                8.   log (10r) = r (in the case of natural logarithms, ln er = r)
                9.   log (1/a) = -log a

# Intro to Complexity Analysis 

        
    
        1. Empirical complexity Analysis (Computational)
            Computational complexity indicates how much effort is needed to apply an 
            algorithm or how costly it is. and in most cases that is concerned with 
            time and space.

                time: is usually more  important!

                The total running time of the program is considered it uses 
                the system's time so it cant be used for measuring [efficiency!] 

        2. Theoretical complexity Analysis (Asymptotic)
            The process of calculating the running time of an algorithm in mathematical units to find the program's limitations, or “run-time performance.” 

    # Running time of a program varies based on 
        - Processor speed 
        - current processor load 
        - inputs size
        - software environment!

            
            
    # Efficiency depends on
        - Execution speed 
        - Amount of memory used

# Whats is time complexity? 
        To estimate how an algorithms performs regardless of the kind of the kind of machine it runs on.
        This time complexity is defined as a function of the input size n using Big-O notation. n indicates the input size, while O is the worst-case scenario growth rate function. 

# How to calculate the time complexity

        Rules:
            - Sequential statements -> O(1)
                function def 
                function return 
                assignment 
                arithmetic operations 
                boolean 
                i/o

            - Conditional statements (worst case is considered)

                Ex.
                    if (isValid) {
                        statement1;
                        statement2;
                    } else {
                    statement3;
                    }
                
                    T(n) = Math.max([t(statement1) + t(statement2)], [time(statement3)])

            - Loop statements 
                - Linear Time 
                    T(n) = runtime of the block * the number of repetition 

                - Constant Time
                    O(1) cause its constant 

                - Logarithmic Time
                    It will use log values (ex. binary search)

                - Nested 
                    Ex.
                            
                        for (let i = 0; i < n; i++) {
                            statement1;

                            for (let j = 0; j < m; j++) {
                                statement2;
                                statement3;
                            }
                        }
                    T(n) = Math.max([t(statement1) + t(statement2)], [time(statement3)])

                    O(n^2)

            - Function calls ? 
                T(n) = 1+ time(parameters) + body time

            - Recursive functions ?

# Algorithm Analysis 

    # Categories 

        - Best Case [Big Omega]
            data: Arranged in the most advantages order 
            T(n): lower boundary 
            input size: minimum input size 

        - Average Case [Big Theta]
            data: Arranged in random order 
            T(n): optimal bound 
            input size: random or average size 

        - Worse Case [Used for complexity Analysis] [Big O]
            data: Arranged in the most disadvantages order 
            T(n): upper boundary
            input size: Infinite size 

    # Order of magnitude 
         The rate ate which the storage and time grows as the function of problem size (n) and its expressed in terms of tis relationship to some known function
         [Asymptotic Analysis]

# Types of Asymptotic Notations 
    - Big-O
    - Big-Omega 
    - Big-Theta
    - Little o(small o)

# Big-O Notations

        The most commonly used complexity for estimating 
        the rate at which a function grows!

    Definition 1: f (n) is O(g(n)) if there exist positive numbers c and N such that f (n) ≤ cg(n) for all n ≥ N.

# Recursion
    Note:
    recursive function uses LIFO (LAST IN FIRST OUT) Structure just like the stack data structure.

    The process in which a function calls itself directly or indirectly is called recursion and the corresponding function is called a recursive function.


    # Properties
        - same operation multiple times
        - smaller inputs to make the problem smaller
        - Base condition is needed to stop the recursion


    # How are problems solved with recursion
        idea is to represent a problem in terms of one or more smaller problems, and add one or more base conditions that stop the recursion.

    # Overflow error
        Stack overflow error occurs in recursions when the base case is not reached or not defined!


    # Types of Recursions

        # Direct
            Calls its self.

        # Indirectly
            Calls another function

            Ex.

            ```
                void indirectRecFun1()
                {
                    // Some code...

                    indirectRecFun2();

                    // Some code...
                }
                void indirectRecFun2()
                {
                    // Some code...

                    indirectRecFun1();

                    // Some code...
                }
            ```
        # Tailed vs Non-tailed
            when the recursive call is the last thing executed by the function

    # Problems of recursive functions

        - greater space requirement
        - greater time requirement
        - difficult code to understand


    # Summary of Recursion:
            #   There are two types of cases in recursion i.e. recursive
                case and a base case.

            #   The base case is used to terminate the recursive
                function when the case turns out to be true.

            #   Each recursive call makes a new copy of that method in
                the stack memory.

            #   Infinite recursion may lead to running out of stack memory.

                Examples of Recursive algorithms:
                Merge Sort, Quick Sort, Tower of Hanoi, Fibonacci Series, Factorial Problem, etc.

# Linked List: 
        Is a collection of nodes storing data and links to other nodes in the chain.
            Node: 
                info [data] 
                next [address]

        # Single Linked List:
            [only has the address of the successor node in the sequence]

            Items are stored in a chain of cells that don't need to be sequential memory addresses because each cell is allocated as needed and has a pointer to indicating the address of the next cell in chain.

                Drawbacks:
                    -> cant instantly retrieve the nth item you have to search starting from the first cell.
                    -> if given only an address of a single cell its not easy to remove it or move backwards with no added information about the previous cell.
            
        # Double Linked List:
            It has an extra cell keeping two pointes to next/previous cells.

        # Circular Linked List:
            The last item in chain is linked to the first item


        # Creating Tail's 
            -> just like head tails keep track of the last element in the Linked List

    # Operations on Linked Lists 

        # Insertion
            [Singly Linked List]

                # Front [done]
                    [4 Steps]
                        1, allocate node 
                            Node* newNodeAdded = new Node();

                        2, put in the data 
                            newNodeAdded->data = "From Loop Node";

                        3, make next of the node as head 
                        newNodeAdded->next = tempTrack;

                        4, move head to point to the new node 
                            head = newNodeAdded;

                    Time Complexity: 
                        O(1), We have a pointer to the  head and we can directly attach a node and change the pointer. So the Time complexity of inserting a node at the head position is O(1) as it does a constant amount of work.
                    Auxiliary Space: O(1)

                # After a given Node 
                
                # End 
                    [5 Steps]
                            1, allocate node 
                                Node* newNodeAdded = new Node();

                            2, put in the data 
                                newNodeAdded->data = "From Loop Node";

                            3, If list is empty then the new node becomes the only node

                            4, Else Traverse until you get to node->null and then insert the node after the last node and 
                            node->next = newNode->next = NULL



            [Doubly Linked List]
            [Circular Linked List]

# Stack's 

    Stack is a linear data structure which follows a particular order in which the operations are performed. The order may be LIFO(Last In First Out) or FILO(First In Last Out).    
    


    Formally, a stack is an abstract data type (ADT) such that an instance S supports the following two methods:
        push(e):  Add element e to the top of stack S.
        pop( ):   Remove and return the top element from the 
                    stack S; an error occurs if the stack is empty.
    
    Complexity O(1)


    Additionally, let us define the following accessor methods for convenience:
        top( ):   Return a reference to the top element of stack 
                    S, without removing it; an error occurs if the stack is empty.
                    
        is empty( ): Return True if stack S does not contain 
                        any elements.
        len(S):     Return the number of elements in stack S; in 
                    Python, we implement this with the special method len .

# Queue's 

    Queue is another form of linear data structure where an item can be inserted at one end and can be removed from another end.
    Addition of a new element occurs at one end called REAR and deletion of an element occurs at another end called FRONT

    Enqueue(): Add an element to the REAR 
    Dequeue(): Remove the element from the FRONT

    Complexity O(1)

# Searching 

    Searching is the process of finding some particular desired element with a particular value in a particular collection of elements.

    # Linear [sequential search algorithm]
        Linear Search is defined as a sequential search algorithm that starts at one end and goes through each element of a list until the desired element is found, otherwise the search continues till the end of the data set.

        Given an array arr[] of N elements, the task is to write a function to search a given element x in arr[].


        Time Complexity
        Best Case               O(1)
        Average Case            O(n)
        Worst Case              O(n)

    # Binary search
        Binary Search is a searching algorithm used in a sorted array by repeatedly dividing the search interval in half. The idea of binary search is to use the information that the array is sorted and reduce the time complexity to O(Log n). 
    
       
        The basic steps to perform Binary Search are:

            -   Begin with the mid element of the whole array as a 
                search key.
            -   If the value of the search key is equal to the item then 
                return an index of the search key.
            -   Or if the value of the search key is less than the item
                in the middle of the interval, narrow the interval to the lower half.
            -   Otherwise, narrow it to the upper half.
            -   Repeatedly check from the second point until the value is
                found or the interval is empty.
        
        Time Complexity
        Best Case               O(1)
        Average Case            O(logn)
        Worst Case              O(logn)


        Binary Search Algorithm can be implemented in the following 
        two ways
        
        # Iterative Method
            binarySearch(arr, x, low, high)
                repeat till low = high
                    mid = (low + high)/2
                        if (x == arr[mid])
                        return mid
        
                        else if (x > arr[mid]) // x is on the right side
                            low = mid + 1
        
                        else                  // x is on the left side
                            high = mid - 1

        # Recursive Method
            binarySearch(arr, x, low, high)
                if low > high
                    return False 
        
                else
                    mid = (low + high) / 2 
                        if x == arr[mid]
                        return mid
            
                    else if x > arr[mid]        // x is on the right side
                        return binarySearch(arr, x, mid + 1, high)
                    
                    else                        // x is on the left side
                        return binarySearch(arr, x, low, mid - 1) 

# Sorting

    A Sorting Algorithm is used to rearrange a given array or list of elements according to a comparison operator on the elements. The comparison operator is used to decide the new order of elements in the respective data structure.

    # Selection Sort 
        The selection sort algorithm sorts an array by repeatedly finding the minimum element (considering ascending order) from the unsorted part and putting it at the beginning. 

        The algorithm maintains two sub-arrays in a given array.
            The sub-array which already sorted. 
            The remaining sub-array was unsorted.

        Time Complexity
        Best Case               O(n^2)
        Average Case            O(n^2)
        Worst Case              O(n^2)

    # Insertion Sort

    # Bubble Sort 

    # Bucket Sort 
        sorting technique that uses the Scatter-Gather-Approach tries to simplify such complex problems by first scattering the complete data into clusters, solving these sub-problems individually, and finally gathering them all together to get the final result.

        The algorithm works by distributing the elements of an array into a number of buckets, Sort the individual buckets, and then gather them all together to form the final sorted array. Each bucket is then sorted individually, using any of the suitable sorting algorithms, or by recursively applying the bucket sorting algorithm.


        bucketSort(arr[], n)
            1) Create n empty buckets (Or lists).
            2) Do following for every array element arr[i].
            .......a) Insert arr[i] into bucket[n*array[i]]
            3) Sort individual buckets using insertion sort.
            4) Concatenate all sorted buckets.

    # Shell Sort 

# Tree's